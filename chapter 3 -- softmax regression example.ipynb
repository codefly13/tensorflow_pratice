{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow的一个简单使用，步骤设计公式，使用eval或者run喂入数据，并执行设计好的操作  \n",
    "本例子的过程：  \n",
    "1、定义目标公式，即预测值的计算  \n",
    "2、选择loss方法，确定优化目标，如最小化loss  \n",
    "3、训练模型，迭代的喂入数据集合，如一个一个batch  \n",
    "4、使用测试数据对模型进行评测  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 载入mnist数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "mnist = input_data.read_data_sets('MNIST_data/',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练数据\n",
    "print(mnist.train.images.shape),print(mnist.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "(10000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试数据\n",
    "print(mnist.test.images.shape),print(mnist.test.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 784)\n",
      "(5000, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证数据\n",
    "print(mnist.validation.images.shape),print(mnist.validation.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入tensorflow后，需要注册session，session是相互独立的，会运行session中的操作。\n",
    "# InteractiveSession是注册是一个session，所有操作默认使用这个session\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义目标函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用placeholder，定义输入的数据。该函数第一个参数是数据类型，第二个参数是数据的维度，如[None, 784]，None表示行数不限制，列统一是784列。\n",
    "x = tf.placeholder(tf.float32,[None, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义变量，在模型训练过程中，会不断更新。变量需要进行初始化，在复杂网络中，初始化方法很重要。\n",
    "# 变量与placeholder的于别是，placeholder使用掉，就会消失。\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 简单的softmax方法，y=softmax(Wx+b)，转化为tensorflow的代码如下\n",
    "y = tf.nn.softmax(tf.matmul(x,W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用tensorflow的一大有点是，他提供了自动求导，使用梯度下降进行forward和backward\n",
    "# 现在有了sorftmax预测目标的方法，只需定义一个损失函数（loss）就可以确定目标函数了，用梯度下降最小化目标函数即可\n",
    "# loss越小，说明预测值与真实值的  偏差  越小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "交叉熵是一种，可以作为损失函数，用于度量模型对真实概率分布估计的准确度\n",
    "\n",
    "$ H_{y'}(y)=-\\sum_{i}y_{i}' log(y_i) $\n",
    "\n",
    "其中$y'$是真实的概率分布（labels的onehot编码），y是预测的概率分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用tesorflow语句自己定义交叉熵\n",
    "# y_预测为真实的概率分布\n",
    "y_ = tf.placeholder(tf.float32,[None, 10])\n",
    "# tf.reduce_mean对每个batch结果求均值，tf.reduce_sum是实现公式中的求和，reduction_indices求和的维度，现在是axis了\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientDescentOptimizer可以直接对目标函数引用梯度下降和反向传播进行求解，初学者会用就行。\n",
    "# 如果想要设计新的优化算法，或者对比不同的优化算法，那需要了解求解过程\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化变量并训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型设置好后，训练模型前，需要对所有变量进行初始化\n",
    "init = tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "for i in range(10000):\n",
    "    # 调用方法获取一个batch的数据，100个样本\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    # 用run运行设计好的模型，run中需要给之前定义的placeholder对象喂数据\n",
    "    train_step.run({x: batch_xs, y_:batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算准确度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到模型后，可以使用模型进行预测类标和真实类标进行比较\n",
    "# 这里用到一个函数 tf.argmax，将概率最大的位置作为类标\n",
    "# tf.equal将预测类标与真实类标作==运算,他返回的是bool类型的tensor\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到预测正确与否的判断后，我们对bool型的tensor做类型转换，转换为tf.float32，再使用tf.reduce_mean求出1的比列，也就是准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9221\n"
     ]
    }
   ],
   "source": [
    "# 定义好计算accuracy的计算过程后，可以使用内部的eval方法输入数据并计算结果\n",
    "print(accuracy.eval({x:mnist.test.images, y_:mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
